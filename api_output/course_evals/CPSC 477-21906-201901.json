{
    "crn_code": "21906",
    "Evaluation_Questions": [
        "Your level of engagement with the course was:",
        "What is your overall assessment of this course?",
        "The course was well organized to facilitate student learning.",
        "I received clear feedback that improved my learning.",
        "Relative to other courses you have taken at Yale, the level of <u>intellectual challenge</u> of this course was:",
        "Relative to other courses you have taken at Yale, the <u>workload</u> of this course was:"
    ],
    "Evaluation_Data": [
        [
            2,
            7,
            9,
            6,
            1
        ],
        [
            9,
            5,
            6,
            5,
            2
        ],
        [
            6,
            9,
            6,
            4,
            2
        ],
        [
            4,
            7,
            7,
            6,
            3
        ],
        [
            0,
            2,
            12,
            11,
            2
        ],
        [
            0,
            5,
            16,
            5,
            1
        ]
    ],
    "Comments_Questions": [
        "What knowledge, skills, and insights did you develop by taking this course?",
        "What are the strengths and weaknesses of this course and how could it be improved?",
        "Would you recommend this course to another student? Please explain."
    ],
    "Comments_List": [
        [
            "\u00a0Various probabilistic models for NLP, part of speech tagging, document classification, sentiment analysis, machine translation, semantic parsing, and how to implement neural networks to solve these problems. ",
            "\u00a0I learned a ton about NLP concepts and techniques ",
            "\u00a0Learned a lot about history of NLP and major technologies/developments in the field ",
            "\u00a0A very rapid-fire, high-level overview of the big problems and tasks that are involved in natural language processing. ",
            "\u00a0A broad scope of topics pertaining to language technology & nlp ",
            "\u00a0A better understanding of natural language processing as a field and some techniques people are using. ",
            "\u00a0I learned a variety of topics in NLP: linguistics, part of speech tagging, parsing, semantic analysis, machine translation, neural networks, etc. I also learned important concepts related to these topics (ex: the Naive Bayes Theorem, Hidden Markov Model, backpropagation in neural networks, gradient descent, etc.) ",
            "\u00a0I learned a lot about natural language processing. It is a very interesting field of study with a lot of work being done right now. ",
            "\u00a0How to read code package manuals ",
            "\u00a0basic understanding of ML and NLP techniques / concepts ",
            "\u00a0overview of NLP, some linear algebra ",
            "\u00a0NLP ",
            "\u00a0This class is a survey of NLP concepts, most memorable of which are the Viterbi and Forward algorithms. In addition, we learned some basic structure of deep learning code for NLP tasks in Google colab. ",
            "\u00a0Overview of NLP ",
            "\u00a0This is a survey course that covers several concepts in NLP.  In particular, we learned about hidden Markov models, neural network architectures, parsing, and NLP applications such as information retrieval and question answering.  Programming assignments were done in Python using the NLTK toolkit and Pytorch. ",
            "\u00a0I learned the general basics of NLP and some of the mathematical concepts that underpin it. ",
            "\u00a0I learned about different problems in NLP (translation, part of speech tagging, etc.) and some techniques and algorithms used to solve them, especially neural networks. ",
            "\u00a0A lot of NLP stuff. Some techniques for tasks such as sentiment analysis, PoS tagging, an introduction to neural methods for translation, semantic parsing. ",
            "\u00a0Honestly, nothing. I learned so little from this class. NOTHING. "
        ],
        [
            "\u00a0I'm not gonna talk about strengths because I don't think there's any.\r\n\r\nI don't really like any of the homeworks except for the second one, where we actually got to implement the viterbi algorithm in code ourselves. The first homework was extremely easy because it was just an introduction to Python and was pretty useless for someone already with background in Python. ALL OF THE OTHER HOMEWORKS WERE REALLY HARD. Hard not in the sense that they are intellectually challenging, but in the sense that they never taught you how to solve it. Most of the time it was just looking up functions in documentations of PyTorch of TensorFlow to write neural networks, except we often cannot figure out which function to look for in the first place. The 3rd homework was especially outrageous because the whole homework was literally filling in 15 lines of Python code and all of those lines are just plugging in some random library functions that they never taught us about (my friends and I all ended up going to office hours and the TA just told us the code, character by character, and in the end nobody learned what the functions meant and how they are supposed to be used).\r\n\r\nThe official prereq for this class is CS223, but seriously if you want to understand the stuff you need to have taken at least Linear Algebra, Probability Theory, and Machine Learning. Radev literally flew through eigenvectors, eigenvalues, and singular value decomposition in a few slides, and I can't imagine how I would have survived without having taken MATH 222. He talked a lot about advanced neural network methods but in the end you will most likely just end up with a vague conceptual idea of what's going on, and I think if you want to learn the details, take Machine Learning. ",
            "\u00a0It is unclear whether it is a strength or a weakness, but the course puts greater emphasis on computational linguistics and historical development of NLP than analogous courses in other universities. ",
            "\u00a0The course material is definitely a strength, it's fascinating. The way it is presented is a weakness. Lectures were kind of hard to follow with not in depth or rushed explanations. ",
            "\u00a0The course covers way too much content without depth, even for a survey course, so students have to spend a lot of time on their own learning the material ",
            "\u00a0While it is helpful to get a high-level overview of the field as a whole, I felt like I walked away from the class without a lot of specific knowledge or information. I would have preferred to spend more time focusing in on a handful of specific tasks in NLP and discussing existing methods to solve them in-depth. Instead, the lectures jumped from topic to topic often and I felt like we never had the opportunity to sit still and really think through a problem. ",
            "\u00a0I like that the course covers a broad number of topics but I wish we would go into more specifics about some of the theory and methods used. ",
            "\u00a0Strengths: the subject itself is very fascinating, and the course certainly covered a wide range of topics related to NLP. Not only did I learn about different NLP applications, I also learned about important algorithms and techniques used to accomplish these tasks. \r\nWeaknesses: the 1st pset was incredibly challenging, but I at least understood what I was doing. The last 2 psets were much easier in the sense it was modeling your code after code that had already been written and only writing about 15 lines out of hundreds that had already been written for you. However, during these last 2 psets I didn't completely understand the code and what I was writing. It would've been helpful to talk more about code rather than just NLP concepts in class, if the psets were going to involve code we had never seen before. Also, it was very difficult to know what was going to be tested on the midterm/final. The class covers A LOT of topics, there are a lot of slide decks, and the midterm asked very specific questions about a wide range of topics. I was not able to answer all of the questions because I couldn't remember every single thing on all of the slides. ",
            "\u00a0Drago is a great professor. I enjoyed the lectures and material. This class lacks in its HW. We do not go over any code in class however the code requires extensive use of libraries we never learn about. Most of the time full solutions can also be found online. I wish more of the HW related directly with techniques covered in class and required more original problem solving. ",
            "\u00a0The problem sets are very arbitrary. ",
            "\u00a0The psets didn't teach anything, and the class focused on techniques that were all outdated or very difficult to reproduce ",
            "\u00a0very poorly structured -- lecture slides totally disorganized and difficult to study from. lectures are difficult to follow / remain engaged with. psets do not facilitate deep understanding of the material, only provide cursory introduction to the concepts. I was very very reliant on TA help. We didn't cover any of the essential math in class, but were still expected to know / tested on it, which didn't work out well for me since I haven't done linear algebra since high school. the exams were ridiculous, too -- we were expected to know EVERYTHING IN DEPTH. I did fine because I spent many hours reading Medium articles and watching youtube videos, so it's definitely do-able. But certainly not preferable. however, I did learn a decent amount and it's your only option if you want to learn about NLP (which is worthwhile). ",
            "\u00a0This class covers a lot of topics but doesn't really go in depth at all. ",
            "\u00a0Strength: very comprehensive overview\r\nWeakness: can provide more details ",
            "\u00a0Strengths: introduces us to a large range of concepts in NLP, great availability of TA/ ULA office hours. \r\n\r\nWeaknesses: Most problem sets are not well-designed to consolidate concepts and algorithms learned in class. For example, we hear about the Malt-Parser algorithm but never had to implement it in code, which could have helped us understand the material better before the exam. ",
            "\u00a0The course started off interesting; however, it quickly became just an whirlwind of introducing topics in NLP by name and not going in-depth at all. For exams and some homework assignments, we were expected to know the material far more in-depth than we were ever prepared for in class. Its not a very well-planned course in that respect. ",
            "\u00a0It tries to give over view of NLP but Professor Radevs presentation and materials are very disorganized. He just look for stuff online and post it on piazza. And the slides are hard to understand if you just read them. This course was more like Reading Stanfords Speech and Language Processing textbook and Towards Data Science blog to me, and also, Advanced Googling techniques ",
            "\u00a0The course material was very interesting, and the lectures were engaging.  The lecture notes were organized well and were helpful study aids.  Since it was structured as a survey course, we were able to learn about a multitude of topics from an exciting field with rapid developments.\r\n\r\nThere is room for improvement in the homework assignments; the first three were directly applicable to class material; however, the fourth and fifth homework assignments provided less of an opportunity to reinforce concepts. ",
            "\u00a0The strength of the course is that you get with a basic vocabulary of NLP terms, but the lectures need to be structured better to facilitate engagement with the material. The problem sets are also obscure and do not facilitate a lot of learning, and often ask questions on topics that were never covered in class. ",
            "\u00a0The material is cool but the course is not well organized. I often didn't understand concepts until much later in the course because the foundational material would be presented after the more complicated concepts. ",
            "\u00a0The lectures for this course aren't great, you don't feel like you're learning anything and the same topics get repeated many times. However then random stuff from the lecture slides can appear on the midterm or final. The psets were not too difficult and the results you get are cool, plus you experience using pytorch and other Python libraries. But the last two psets were kind of fill-in-the-blank style and you really didn't have to understand what was going on if you weren't super interested. ",
            "\u00a0The psets were good, but the amount of course content is somewhat overwhelming and the slideshows are extremely long and disorganized. More references to textbook sections would be super helpful. ",
            "\u00a0Where to even begin? This course needs a total makeover. Its lectures (and the slides that accompany them) are inscrutable. Its homeworks are total wastes of time. There is nothing good about this course. The exams expected far too much of the students. Nothing was actually taught in this course. Nothing. It was as if we were supposed to know everything already and Drago was just reviewing the concepts for us, saying a few buzzwords and expecting it to sink in. The class covers way too much material, way too fast. There is no teaching. He basically laundry lists the stuff you're supposed to know for the exam (a mind-boggling amount of content), except it's supposed to be a lecture. Most lectures explain concepts to you. This is not the case with Drago's lectures. It's impossible to take notes on what is being presented. And the homeworks? My god. Somehow, they managed to walk the previously-thought-to-be-invisible line between being extremely conceptually difficult and being so trivial that there is nothing to be learned. The problem sets were way too hard for us to do, so to compensate for that, they were mostly already done for us when we started coding them. All that remained was to copy and paste a few lines of code from one box to another, slightly changing a variable here and there. Most of it was blind testing. Very little learning to be had. Even the third homework, which was not coding but math, was totally unhelpful to creating any kind of understanding in the class. I can't believe this is a course that is taught. This class needs a new... everything. It's shameful that this is the introduction to NLP at Yale. "
        ],
        [
            "\u00a0I wouldn't. The lectures are subpar and I'm not sure the way Radev organizes his slides is intuitive for people to understand and helpful for looking up material (he names the slides with arbitrary 3 digit numbers and no one except himself knows which number corresponds to which topic--you had to refer to Piazza posts every time to figure it out). The lectures just fly through the material pretty quickly and don't go into depth. In the end, the impression I got out of most of the lectures was just that Oh there is this thing called machine translation/part of speech tagging, but I don't think I learned anything useful in lecture about HOW to solve those problems algorithmically. In fact, don't even bother going to lecture; reading the textbook on your own is probably more useful.\r\n\r\nI've also heard that the homeworks are all written by the ULAs/TAs, and they can vary greatly in quality. 4 out of 6 of the homeworks were about neural network implementation using PyTorch or TensorFlow and they were really confusing because no one taught us about the library functions. ",
            "\u00a0Yes: the course is an excellent intersection of CS, linear algebra, statistics, and linguistics applied to a practical purpose. ",
            "\u00a0Hard to say. The field of NLP is fascinating and amazing to learn about. The class NLP isn't the best, though it does expose you to a lot of interesting material and ideas. If you like NLP or linguistics, then at least shop this class. ",
            "\u00a0If you are interested in NLP, there are great online resources to help you, and several professors doing great research here at Yale who can help show you the ropes. I don't think this class offers a very thorough introduction to the field. ",
            "\u00a0Yes! It is such a cool topic & Professor Radev does great work in his lab ",
            "\u00a0If you are interested in linguistics and cs then I would recommend. ",
            "\u00a0I would recommend it for a student who wants to learn more about NLP. I personally think NLP is a very interesting topic, and this course covers a wide range of NLP applications, concepts, algorithms, etc. For example, I now have a much better understanding of how neural networks work. Drago is also a very friendly and accommodating professor. However, I do think that the course could be organized a bit better, in the sense that I did not feel prepared for the midterm/final because it was unclear what we needed to know. The course covers so many topics that it is impossible to memorize everything on every powerpoint, but the exams did test a very wide range of topics/asked specific questions. ",
            "\u00a0If they made better HW assignments yes. ",
            "\u00a0no.  Just learn the material on your own. ",
            "\u00a0Yes. ",
            "\u00a0Take the class if you are comfortable with the idea that you will leave thos survey class with a mere surface-level understanding of each concept. Prof Drago goes through the slides at lightning speed, so there is A LOT OF material to cram in for the exam. However, the slides as well as the book are very informative, so people generally do well in the class even though most stopped going to lecture a few weeks in. There are other CS electives that are much better at helping students build coding skills. However, if you are very interested in the topic of NLP itself, this is a nice, gentle introduction. ",
            "\u00a0I wouldnt recommend the course. The material we expected to know (and thus the difficulty) of the problem sets and exams were very unpredictable and sometimes seemed arbitrary. One question on the midterm exam was literally I mentioned the word acerola in lecture once - what was the context?... ",
            "\u00a0No please dont take this course itll ruin your yale experience. Id rather have no skills for job hunting than taking this course. ",
            "\u00a0If you have any interest in NLP, or AI in general, you should definitely take this course!  Conceptual understanding is more important than programming prowess, so the course is definitely accessible to non-CS majors, as well. ",
            "\u00a0If you are really invested in learning NLP and want an extremely basic overview of the field you can consider this course, but there are much better electives out there. ",
            "\u00a0I'm mixed on this course. On the one hand, the underlying information is really really cool and if you're interested in the material it could be a great experience. On the other hand, you have to be willing to study the material on your own time to really understand it because the lectures are often not well organized. ",
            "\u00a0Probably should have taken AI, I just didn't want a Friday class \\_()_/ ",
            "\u00a0Yeah. It was a fun course and if you're into AI or languages or both, this is a fun one. ",
            "\u00a0No. Heck no. Never. Even if you're interested in NLP, just take Computational Linguistics in the fall. This class is one of my biggest regrets. Seriously, it was such a waste of time. I went through pretty much all of Yale until now thinking that I was going to love NLP. It was my motivation until now. I am sad to say that NLP is dead. Forever. Drago killed it. There is nothing here to love. Please, for the love of God, take something else. Please. Please. Please. "
        ]
    ]
}