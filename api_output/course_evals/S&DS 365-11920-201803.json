{
    "crn_code": "11920",
    "Evaluation_Questions": [
        "Your level of engagement with the course was:",
        "What is your overall assessment of this course?",
        "The course was well organized to facilitate student learning.",
        "I received clear feedback that improved my learning.",
        "Relative to other courses you have taken at Yale, the level of <u>intellectual challenge</u> of this course was:",
        "Relative to other courses you have taken at Yale, the <u>workload</u> of this course was:"
    ],
    "Evaluation_Data": [
        [
            0,
            3,
            7,
            13,
            14
        ],
        [
            2,
            3,
            9,
            11,
            12
        ],
        [
            2,
            4,
            9,
            9,
            13
        ],
        [
            1,
            4,
            9,
            12,
            11
        ],
        [
            0,
            0,
            3,
            23,
            11
        ],
        [
            0,
            0,
            9,
            16,
            12
        ]
    ],
    "Comments_Questions": [
        "What knowledge, skills, and insights did you develop by taking this course?",
        "What are the strengths and weaknesses of this course and how could it be improved?",
        "Would you recommend this course to another student? Please explain."
    ],
    "Comments_List": [
        [
            "\u00a0I learned more about machine learning and data models than I thought possible.  From word embedding to all sorts of regression and classification, I gained valuable experience. ",
            "\u00a0Machine learning techniques and coding in r ",
            "\u00a0I learned detailed insights into both the concepts behind machine learning techniques as well as hands-on experience in applying those techniques to real world data, mostly in R but also in Python towards the end of the semester for NLP. ",
            "\u00a0I learned so much about supervised and unsupervised learning techniques. This is a great class to learn about modeling and machine learning methods. Its a great balance between theory and application. ",
            "\u00a0Mostly supervised machine learning ",
            "\u00a0R, basic machine learning concepts ",
            "\u00a0You will learn the math behind a lot of commonly used machine learning algorithms, and implement using public datasets in R and python. \r\n\r\nYou never learn how to deal with data collection, cleaning, and manipulation though. ",
            "\u00a0A decent knowledge of how to implement and understand various machine learning algorithms ",
            "\u00a0I learned about bias/variance trade-offs, how to program in R, classical machine learning tools (random forest, boosting, logistic regression), and some new \"deep learning\" tools like autoencoders, and latent dirichlet allocation. ",
            "\u00a0Machine learning statistical models, basic programming techniques related to machine learning such as coding a simple 2/3-layer neural network ",
            "\u00a0I learned so much about the theory behind modern machine learning techniques, as well as how to implement them. I improved my programming, quantitative reasoning, and data analysis skills. ",
            "\u00a0Basic machine learning methodology, some non-neural-network techniques, and R programming. ",
            "\u00a0I learned about regressions, classifications, decision trees, topic models, and a little bit of neural networks, which is pretty standard for a statistical machine learning class. As a stats class, I learned very little of the math and intuition behind these topics; they were skimmed over during class and the derivations on the pset did nothing to increase my understanding. I also learned some R, basically on my own, as the one tutorial session only covered basic syntax leaving us to figure out all the packages on our own. As a CS major, I did not feel prepared by this course to tackle the psets without substantial learning and would recommend that better R resources be provided. ",
            "\u00a0A moderate understanding of essential machine learning topics like Linear and logistic Regression, Topic models, Neural language models, autoencoders and neural nets ",
            "\u00a0Concretely, this course exposes students to a range of machine learning techniques and applications.  I feel that I gained insight into the intuition behind various algorithms and the goals of machine learning, as well as practical coding skills in R and Python. ",
            "\u00a0I learned A LOT about the fundamental algorithms that encompass machine learning (linear regression, lasso regression, stochastic gradient descent, and a lot more!) and got to have a basic-medium understanding of deep neural networks and language models. This class was fantastic! ",
            "\u00a0Topics related to machine learning starting from statistical techniques including: linear regression, classification (Bayes classifier, linear and quadratic discriminant analysis, logistic regression), regularization, decision trees, random forest, bagging and boosting algorithms, Bayesian statistics and hierarchical models (specifically, topic modeling), word embeddings, sparse coding, and neural networks. ",
            "\u00a0I learned the basics of machine learning and data mining: linear regression, topic modeling, neural networks etc. ",
            "\u00a0Knowledge: Supervised and unsupervised machine learning techniques; mainly overviewing their math and implementation and then practicing using them on various datasets. Linear regression, variable shrinkage, bias and variance, trees, boosting, SGD and non-linear / neural methods; topic models, language models, embeddings, clustering, gaussian mixtures, and SSL.\r\nSkills: Some fundamental math and implementation of methods; practice using the software and getting intuition for the tradeoffs.\r\nInsights: unsupervised techniques can often be cast as supervised problems (e.g. language models use words to predict future words in the document); and unsupervised methods increase data efficiency on large datasets. Intuitions about bias and variance and model selection accross problems and areas. Better representations of data is key to prediction; inference about causal truth is hard but sometimes possible. Fairness is very hard and interesting. ",
            "\u00a0Learned about ML algorithms ",
            "\u00a0This course covers a lot of the fundamental topics in machine learning.  The first half of the course covers supervised learning and introduces students to how to think within this field (e.g. oftentimes, the framework follows having a model for a problem we want to solve, having a loss function for that, wanting to minimize the loss, not having a closed-form solution to minimize the loss, and using optimization techniques to then minimize the loss; we do all of this on training and test sets, while also doing cross-validation to tune parameters for the model based on the training set, and then we often think about this in terms of the bias-variance tradeoff). The second half of the course covers unsupervised learning and other topics.\r\n\r\nIn particular, with supervised learning, we study regression and classification tasks, with linear regression and regularization with ridge regression and lasso regression for regression techniques and logistic regression, linear discriminant analysis, and quadratic discriminant analysis for classification techniques. We also study kNN, decision trees, and ensemble methods with random forests, bagging, and boosting.\r\n\r\nWith unsupervised learning, we first think about latent variables. Specifically, we look at models for natural language processing with topic models (with the latent Dirichlet allocation model), language models, and word embeddings. \r\n\r\nWe also study neural networks and autoencoders. ",
            "\u00a0This course covered a wide range of topics including linear regressions, k-nearest neighbors, LASSO and ridge regression, decision trees, topic modeling, word embeddings, and neural networks. This course definitely had a large theoretical component and did rely on knowledge of statistics at the S&DS 242 level. ",
            "\u00a0Data analysis "
        ],
        [
            "\u00a0Strengths: the problem sets were written to really help you learn by doing. By the end of problem sets, I understood the material way better than at the beginning. Lafferty is a pretty good and engaging lecturer, although he can gloss over things and goes every quickly.\r\nWeaknesses: I could never go to any of the TA/professor office hours because they were always held at about the same time (5:30-6:30). For people who have daily/weekly commitments, this can be really hard, especially in a class that claims to be at an \"intro\" level, where it is very difficult to complete the psets without going to office hours. Yes, I could attend some of the ULA office hours, but some of the ULAs were better than others. If a ULA had completed the pset in a past year, they were normally very helpful, but if not, there was sometimes nothing they could really do. Lafferty seemed to give them little in terms of aids to help us. I think the class could benefit from having sections so that everyone could have equal access to homework help and those who could not attend Lafferty's office hours would not feel behind.\r\n Also, the midterm was more on the theoretical side, where the psets were applied in r. Although I knew this would be the case, I found it very hard to study for the midterm because there weren't very many examples of the way the exam would look. We had good practice for the T/F questions,  but I got almost all of the long answer questions wrong because I had no clue what to do. One of them, I would have gotten, but the material was from a problem set that was due two days after the midterm, so it was frustrating. This could be improved by giving more practice exams or having more practice problems available before the quizzes.\r\nI would especially encourage Lafferty to rethink the pset that took about 12 hours to run. That was overly stressful because I wasn't sure if I could complete the pset on time, and I didn't feel like I learned too much from that part. Maybe that pset could have been rewritten so that it was more similar to the python psets at the end, where the code/results were provided, and we only needed to explain the trends. ",
            "\u00a0The first few weeks of the course were much more rigorous in the problem sets, and while they were intense, it forced us to really make sure we understand the math behind what we were doing. After the SGD pset (I think), the psets got a little too simplified to that point that I think we could complete them without really thoroughly understanding the mathematical concepts. I think it's great that Professors Lafferty and Feng took our feedback seriously about the homework being too much to handle in the beginning, but it would have been helpful to find more of a medium in level of difficulty. I personally think that could be achieved by spending more time on fewer topics. ",
            "\u00a0I think maybe having an earlier midterm (instead of mid-November) and maybe one less homework and introducing a final project. A final project might allow students to really dive deep into some of the topics discussed and having a nice independent project to have in their portfolios. ",
            "\u00a0Too fast paced ",
            "\u00a0Strengths: Lafferty is brilliant, and his examples and stories in class are great. He hits most of the topics that people want to learn about. Office hours every day was great.\r\n\r\nWeaknesses: The content tested on the midterm and quizzes was very different than the content in class and on problem sets. I had a 94 average on homeworks and got a 51 on the midterm. One tests coding, one tests math. ",
            "\u00a0Scarcity of resources provided to better learn the material, particularly on generative models. ",
            "\u00a0The problem sets overall were fair and a good way of learning about the material. I would suggest moving more of the assignments (if not the whole course) into Python. ",
            "\u00a0I think a major strength of this course is John Lafferty -- he is an incredibly kind, patient and thoughtful instructor and it was a pleasure being able to learn from him over the course of the semester. The material is interesting as well as it was the first time I learned about the distinction between discriminative and generative models, and how Bayesian methodology differed from Frequentist methodology. ",
            "\u00a0Strength: important material to learn, great selection of topics, the professor so very knowledgeable about the field, problem sets helped reinforce the material\r\nWeakness: some slides could be clearer with communicating information ",
            "\u00a0I wish that the lecture more closely matched the problem sets. You must teach yourself a lot to complete the problem sets. ",
            "\u00a0Interesting materials and good lecturer.\r\n\r\nSome of the mathy details that require advanced statistics are not explored, so students have to take what the professors said as truth some times because they don't know how to prove it. ",
            "\u00a0The lectures are quite unhelpful for gaining intuition - i often went through a couple slides of derivation not knowing any of what we just did, or why. Lafferty's habit of teaching from slides makes it much easier to gloss over the math, which he would have a much better feel for if were deriving things on the fly. There was also an excess of notation and equations to turn intuitive ideas into something needlessly obstruse. Many times students in class had to ask what new variables meant since there was NO explanation given otherwise. ",
            "\u00a0The course has many office hours: at least one every day, and so you could get timely support from ULAs, TAs and Professors. Unfortunately, most of the weekday office hours were held during dinner. Going to office hours often meant having to skip dinner. To make office hours even better, one could hold them before dinner (4-5) or after dinner (7-8). Also, at least twice, I have gone to office hours where the ULA or TA did not know how to do the PSET. To make office hours more time worthy, it will be good to hand the answer keys to the teaching staff every time a PSET is released. \r\n\r\nThe PSETs took a rather long time because they demanded manual coding of inefficient algorithms. The professors eventually loosened the standards of the questions after several students raised concerns about finishing the assignments. Perhaps it will be great to start using the jupyter notebook and computer clusters from the get go, rather than rely on RStudio. ",
            "\u00a0The strengths of the course are the quality (not length) of the problem sets, the variety of topics we covered during the semester, and Prof. Lafferty's lecture style.  The problem sets were great ways of seeing how methods can be applied to real data.  The breadth of the course made me curious to take more machine learning in the future.  Prof. Lafferty's lecture style is straightforward, well-organized, and very clear.\r\n\r\nThe weakness of the class is that the mathematical theory covered in this course is relatively scarce. I would have liked to delve into theory a bit more, as I feel that theory is really the meat of these methods! I would ask Prof. Lafferty to be more willing to delve into mathematical theory during office hours and outside of class.  There were a few times when, after asking for guidance on proofs or deeper math behind ML methods, I got an answer was closer to \"not important for this pset\" than \"sure, here's a way to think through the problem.\"\r\n\r\nLast critique: the psets are instructive but way too long.  Not even the coding part is too bad.  It is more that a few problem sets took forever to run and were just a pain to go through.  Perhaps there is a way to use simpler or cleaner data so that the learning is still there without the 10+ hour runtime on some of these programs we had to write! ",
            "\u00a0I think that we covered a lot of material in one semester, and that we could learn even more if the course were divided in two semesters. I think that the material was awesome and that the professor was very kind and patient and also explained very complex topics as simply as he could. ",
            "\u00a0Strengths were that problem sets were of a moderate difficulty -- difficult enough to be challenging, but not difficult enough for them to be impossible. Weaknesses were that the lectures were too theoretical and most times not useful for completing the problem sets, which meant that there was little incentive to come to lecture. It also meant that I (and many others) felt grossly underprepared for the midterm exam. The lack of a final assessment meant that was little incentive to try after the midterm exam. Official solutions were never provided for any of the problem sets or the midterm exam, which made it difficult to learn from mistakes (the official rationale was that they wanted to use the problems for future semesters, but this is weak reasoning because a future student could just take a past student's working code.) Also, for those of you reading this in the future, beware of Derek Feng is the sole instructor. It was his first semester so the lectures he gave were noticeably weaker than those given by Lafferty, but I think he'll get better. TAs and ULAs were sometimes confused about what was happening in the course, even though they themselves were very competent. ",
            "\u00a0Strengths: you learn a lot of the concepts through the problem sets, and the material is interesting with many applications. Weaknesses: the problem sets took a long time and a lot of office hours, the course moves pretty quickly and covers a lot of topics, so it was hard to learn things in depth. ",
            "\u00a0The psets are very time consuming and it was difficult to study for the midterm because the material didn't translate well from the psets.  The lecture are good if you pay attention but not always very relevant to what is covered in the psets. Some of the office hours were not helpful - it was helpful to work with a group of other students to get through the psets. One strength is that you know exactly what's expected in the course: 7 psets (one of which you can drop), two quizzes and one midterm (no final !) - you just have to power through. ",
            "\u00a0Great lecture by John; pretty good lectures by Derek. Assignments are well thought through. Could have more mathematical and programming depth. It's more of a survey course to develop intutions and familiarity with the methods rather than robust understanding in a way that you can cut your own teeth on fresh research immediately hereafter (maybe that's too much to ask). The good thing about the survey nature of the course is it doesn't have to overly burden you. ",
            "\u00a0Great course, could give more introduction to the mathematical techniques used ",
            "\u00a0This course has by far been one of my favorite courses at Yale, so I believe it has many, many strengths. I have probably learned more in this course than I have in any of my other courses, and everything I learned is just so useful and so fascinating. I absolutely loved this course. The topics we cover in this class are so important to know and understand, and I feel like I grew so much after learning them; I have a better understanding of this field as a whole now that I have taken this course, and it really allows me to understand the context of the work that is being done in this field right now. For me, personally, I also found that the amount of help that is available for this class was extremely beneficial. Being able to have office hours every single day of the week is, in my opinion, the best way to have a class; it allows students to constantly be engaged with the material so that we are always learning, and it allows us to get help and feedback in time for us to catch the flaws in our understanding of the material before they get too ingrained. If I hadn't been able to have this much help and support, I feel like I would have struggled so much, and I probably would not have been able to finish the course. In general, as an overall suggestion to the department as a whole, I think it would be great if we could have this much support in other classes in this department, especially the more advanced courses.\r\n\r\nIn terms of weaknesses of this course, I don't think that there is much to say. I would absolutely love to be able to take a continuation to this course in order to keep learning about this sort of material; I would definitely take one, were it offered next year. Specifically with this course, it would have been nice to have a better balance between R and Python assignments, like half in R and half in Python maybe. I especially would have appreciated having the opportunity to have had some assignments for which I would need to write the Python code entirely on my own instead of being given starter code to go off of. ",
            "\u00a0The course was great overall, I think it had a good balance between the theoretical components and the applications. One weakness was that the course went pretty quickly though very difficult topics towards the end of the semester and it was a little unclear how in depth we were supposed to understand these topics. Another weakness was the that TAs and both professors didn't always seem to be on the same page. I often had the TAs tell me to do one thing, but when I talked to Professor Lafferty he would say that doing it that way was wrong. This was extremely frustrating, because I would oftentimes spend several hours working on something the TA said only to find out it was wrong. It would be nice if there were some more collaboration between everyone. ",
            "\u00a0Weaknesses: this class is offered to graduate students as me and it is called \"Applied Machine Learning\". Yet the class is not applied at all. Furthermore the explanations from Lafferty are cumbersome and difficult to understand for non-mathematicians. "
        ],
        [
            "\u00a0If you have a strong math background and want to learn more about statistics and data science, specifically machine learning, this is a great course for you. However, it is not for those looking for a cool survey course and don't plan on putting in a lot of work. ",
            "\u00a0Yes, if you really want to have an immersion experience in machine learning. I had very little coding experience (cs 112 and a data analysis class in R) and I found it kind of hard to essentially learn to code and absorb the stats information at the same time. This class really took over my life. There were many times when I felt like I could not complete any of the problem set alone without going to office hours. That being said, I do feel like I walked out of the class with a valuable new set of skills and can understand the basics of machine learning. ",
            "\u00a0Yes, definitely take this class as long as you already have background in linear algebra, programming, and of course, statistics. ",
            "\u00a0Absolutely, especially if Professor Lafferty is teaching it. The course material is challenging, but the class is still organized in way for you to easily manage it. If you are interested in data analysis or data science, this class is a must. I really really enjoyed it. ",
            "\u00a0Yes, provides good overview of the basics ",
            "\u00a0If you dont have the prerequisites, you will get absolutely rekt right after the midterms when you do topic models, language models, etc. Its not for the weak. This class is a ton of work. I spent 20~30 hours per pset. That being said, the content is in demand and very practical. ",
            "\u00a0If you want some exposure into machine learning, this is basically the only undergrad class thats available for you. It should really be two classes - one thats applied and one that digs deeper into theory. As it stands, the theoretical aspects are hard to understand/ youre kind of unsupported. ",
            "\u00a0If you're interested in machine learning and have some statistics/math background, I would recommend it. ",
            "\u00a0Yes, you learn a lot and the professor is very knowledgeable about the field ",
            "\u00a0I would recommend the course to anyone looking to learn about this topic, and willing to put in the time. You will really learn so much, because Lafferty's psets are so well-designed. But it will be a huge grind, and you will have to teach yourself some of it. ",
            "\u00a0I would recommend if you haven't known any machine learning. \r\n\r\nI wouldn't if you want to know about neural networks or you don't like R. ",
            "\u00a0Not in its current form, and not without having taken a prior class in R. ",
            "\u00a0Yes, just because this is such an important topic nowadays. ",
            "\u00a0Yes! This course is a great intro to machine learning. I really hope they make an intensive version with more mathematical rigor, but this version is nice if you are not great on the stats but are thinking of getting started. ",
            "\u00a0YES! Take this course! You will definitely learn a lot. However, beware of the amount of work that this course demands. You will definitely spend some time doing the psets for this class, particularly those after mid-semester where training models can range from anything to 4 to 20+ hours depending on your computer model. Do not let this discourage you tho, you will definitely gain a lot out of the class. ",
            "\u00a0Shop it and see. Unfortunately this is the only course that Yale really offers in this area that's also decently accessible (I do believe there's one 400-level course that has more prereqs), and given that ML is a burgeoning field, it's really a shame, especially when other competing schools have much more fleshed-out course offerings. I don't regret taking this course, but felt that it could have been run a lot better. ",
            "\u00a0Yes - I think it was a good introduction to machine learning, but if you want to go into the theory of some of the methods you might need to take some higher level courses. Depending on your background, it could be a lot of work (if you don't have prior exposure to R for example). ",
            "\u00a0I had to take it for my major - if you're passionate about the subject then take it. ",
            "\u00a0I took the course Cr/D as a CS major (does not count towards CS if you choose to Cr/D it tho), and it was well worth it. Great to develop robust intuitions about getting truth from data and-maybe more importantly-avoid getting falsehood from data. ",
            "\u00a0Yes ",
            "\u00a0This has been one of my favorite courses at Yale, and it has probably been my absolute favorite course within the Statistics & Data Science department. What you learn in this course is super, super fascinating and also super, super useful. For me, it put a lot of what I previously learned in statistics into context; it made me realize why the previous things I had learned were important and how they were actually used. I just really love this material. I want to keep studying it. ",
            "\u00a0Definitely! I loved this course and it was amazing to take it with Professor Lafferty. There are a lot of really important topics covered in the course. ",
            "\u00a0I do not recommend this course unless you have a REALLY good level of maths and statistics. \r\nI think the graduate name of this class is misleading since this class is not Applied at all.\r\nI really think this class should be split into two: one mainly targeted for graduate students and more applied, and a different one targeted for maths majors and more fundamental. I think the first class could be extremely useful for graduate students from many schools (e.g. Medicine, Environment, Public Health...) who are really interested in applying these new techniques in their fields but who do not have the interest of fully understanding or developing machine learning algorithms. "
        ]
    ]
}